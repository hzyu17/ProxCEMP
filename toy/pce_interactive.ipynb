{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCE vs NGD vs CasADi: Stability Comparison\n",
    "\n",
    "**Cost function:** $J(x) = (x - 5)^2 + 0.1 x^2 + 100 \\cdot \\mathbf{1}_{(2,3)}(x) + 100 \\cdot \\mathbf{1}_{(6,8)}(x)$\n",
    "\n",
    "**Optimal:** $x^* = \\frac{50}{11} \\approx 4.545$, $J^* = 2.27$\n",
    "\n",
    "**Key insight:** PCE with best-so-far tracking is stable and reaches global optimum, while CasADi (with smooth barrier) gets stuck in local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from ipywidgets import interact, IntSlider\n",
    "from enum import Enum\n",
    "import casadi as ca\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal x* = 4.5455, J* = 2.2727\n"
     ]
    }
   ],
   "source": [
    "def quadratic_state_cost(x, x_star=5.0):\n",
    "    return (x - x_star) ** 2\n",
    "\n",
    "def control_cost(x, R=0.1):\n",
    "    return R * x ** 2\n",
    "\n",
    "def barrier_cost(x, barrier_val=100.0):\n",
    "    \"\"\"Indicator: large cost for x in (2,3) and (6,8)\"\"\"\n",
    "    b1 = np.where((x > 2) & (x < 3), barrier_val, 0.0)\n",
    "    b2 = np.where((x > 6) & (x < 8), barrier_val, 0.0)\n",
    "    return b1 + b2\n",
    "\n",
    "def total_cost(x, x_star=5.0, R=0.1):\n",
    "    return quadratic_state_cost(x, x_star) + control_cost(x, R) + barrier_cost(x)\n",
    "\n",
    "X_STAR = 50 / 11\n",
    "OPTIMAL_COST = quadratic_state_cost(np.array([X_STAR]))[0] + control_cost(np.array([X_STAR]))[0]\n",
    "print(f\"Optimal x* = {X_STAR:.4f}, J* = {OPTIMAL_COST:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovarianceSchedule(Enum):\n",
    "    CONSTANT = 0\n",
    "    LINEAR = 1\n",
    "    EXPONENTIAL = 2\n",
    "    COSINE = 3\n",
    "\n",
    "def compute_covariance_scale(iteration, n_iterations, schedule,\n",
    "    cov_scale_initial=1.0, cov_scale_final=0.01, cov_decay_rate=0.95):\n",
    "    t = float(iteration - 1)\n",
    "    T = float(n_iterations)\n",
    "    if schedule == CovarianceSchedule.CONSTANT: return cov_scale_initial\n",
    "    elif schedule == CovarianceSchedule.LINEAR: return cov_scale_initial + (cov_scale_final - cov_scale_initial) * (t / T)\n",
    "    elif schedule == CovarianceSchedule.EXPONENTIAL: return max(cov_scale_final, cov_scale_initial * (cov_decay_rate ** t))\n",
    "    elif schedule == CovarianceSchedule.COSINE: return cov_scale_final + 0.5 * (cov_scale_initial - cov_scale_final) * (1.0 + np.cos(np.pi * t / T))\n",
    "    return cov_scale_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCE Algorithm (with best-so-far tracking for stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pce_with_history(cost_fn, y_init=0.0, sigma_init=2.0, n_samples=100, n_iterations=50,\n",
    "    elite_ratio=0.1, ema_alpha=0.5, gamma=1.0, temperature=1.5, temperature_final=0.05,\n",
    "    cov_schedule=CovarianceSchedule.COSINE, cov_scale_initial=1.0, cov_scale_final=0.01, cov_decay_rate=0.95):\n",
    "    \n",
    "    y = y_init\n",
    "    y_best = y_init  # KEY: Track best solution found\n",
    "    cost_best = cost_fn(np.array([y_init]))[0]\n",
    "    n_elites = max(1, int(n_samples * elite_ratio))\n",
    "    \n",
    "    history = {'y': [y], 'y_best': [y_best], 'sigma': [sigma_init * cov_scale_initial],\n",
    "               'cost': [cost_best], 'cost_best': [cost_best],\n",
    "               'temperature': [temperature], 'samples': [], 'sample_costs': [],\n",
    "               'elite_indices': [], 'elite_weights': [], 'weighted_y': []}\n",
    "    \n",
    "    for iteration in range(1, n_iterations + 1):\n",
    "        progress = (iteration - 1) / max(1, n_iterations - 1)\n",
    "        current_temp = temperature * (temperature_final / temperature) ** progress\n",
    "        cov_scale = compute_covariance_scale(iteration, n_iterations, cov_schedule,\n",
    "            cov_scale_initial, cov_scale_final, cov_decay_rate)\n",
    "        effective_sigma = sigma_init * cov_scale\n",
    "        \n",
    "        # KEY FIX 1: Sample around BEST solution (not current y)\n",
    "        epsilon = effective_sigma * np.random.randn(n_samples)\n",
    "        samples = y_best + epsilon\n",
    "        costs = cost_fn(samples)\n",
    "        elite_indices = np.argsort(costs)[:n_elites]\n",
    "        \n",
    "        weights = np.zeros(n_samples)\n",
    "        for m in elite_indices:\n",
    "            weights[m] = np.exp((-gamma * costs[m]) / current_temp)\n",
    "        weights /= (np.sum(weights[elite_indices]) + 1e-10)\n",
    "        x_weighted = sum(weights[m] * samples[m] for m in elite_indices)\n",
    "        \n",
    "        history['samples'].append(samples.copy())\n",
    "        history['sample_costs'].append(costs.copy())\n",
    "        history['elite_indices'].append(elite_indices.copy())\n",
    "        history['elite_weights'].append(weights[elite_indices].copy())\n",
    "        history['weighted_y'].append(x_weighted)\n",
    "        \n",
    "        # Compute candidate\n",
    "        y_new = (1 - ema_alpha) * y_best + ema_alpha * x_weighted\n",
    "        cost_new = cost_fn(np.array([y_new]))[0]\n",
    "        \n",
    "        # KEY FIX 2: Only update y_best if improvement (monotonic!)\n",
    "        if cost_new < cost_best:\n",
    "            y_best = y_new\n",
    "            cost_best = cost_new\n",
    "        \n",
    "        y = y_new  # Track raw trajectory\n",
    "        history['y'].append(y)\n",
    "        history['y_best'].append(y_best)\n",
    "        history['sigma'].append(effective_sigma)\n",
    "        history['cost'].append(cost_new)\n",
    "        history['cost_best'].append(cost_best)\n",
    "        history['temperature'].append(current_temp)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGD Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ngd_with_history(cost_fn, y_init=0.0, sigma_init=2.0, n_samples=100, n_iterations=50,\n",
    "    learning_rate=0.1, temperature=1.0, cov_schedule=CovarianceSchedule.COSINE,\n",
    "    cov_scale_initial=1.0, cov_scale_final=0.01, cov_decay_rate=0.95):\n",
    "    \n",
    "    y = y_init\n",
    "    prev_cost = cost_fn(np.array([y]))[0]\n",
    "    \n",
    "    history = {'y': [y], 'sigma': [sigma_init * cov_scale_initial], 'cost': [prev_cost],\n",
    "               'temperature': [temperature], 'samples': [], 'sample_costs': [], 'gradient': [], 'epsilon': []}\n",
    "    \n",
    "    for iteration in range(1, n_iterations + 1):\n",
    "        cov_scale = compute_covariance_scale(iteration, n_iterations, cov_schedule,\n",
    "            cov_scale_initial, cov_scale_final, cov_decay_rate)\n",
    "        effective_sigma = sigma_init * cov_scale\n",
    "        \n",
    "        epsilon = effective_sigma * np.random.randn(n_samples)\n",
    "        samples = y + epsilon\n",
    "        costs = cost_fn(samples)\n",
    "        natural_gradient = np.mean((costs / temperature) * epsilon)\n",
    "        \n",
    "        history['samples'].append(samples.copy())\n",
    "        history['sample_costs'].append(costs.copy())\n",
    "        history['gradient'].append(natural_gradient)\n",
    "        history['epsilon'].append(epsilon.copy())\n",
    "        \n",
    "        y = y - learning_rate * natural_gradient\n",
    "        history['y'].append(y)\n",
    "        history['sigma'].append(effective_sigma)\n",
    "        history['cost'].append(cost_fn(np.array([y]))[0])\n",
    "        history['temperature'].append(temperature)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CasADi Solver (with smooth barrier approximation k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_casadi_with_history(y_init=0.0, x_star=5.0, R=0.1, k=2):\n",
    "    \"\"\"CasADi with smooth sigmoid barrier approximation.\n",
    "    Lower k = smoother = more artificial local minima!\"\"\"\n",
    "    x = ca.SX.sym('x')\n",
    "    base_cost = (x - x_star)**2 + R * x**2\n",
    "    barrier1 = 100.0 * (1 / (1 + ca.exp(-k*(x - 2)))) * (1 / (1 + ca.exp(k*(x - 3))))\n",
    "    barrier2 = 100.0 * (1 / (1 + ca.exp(-k*(x - 6)))) * (1 / (1 + ca.exp(k*(x - 8))))\n",
    "    J = base_cost + barrier1 + barrier2\n",
    "    grad_J = ca.gradient(J, x)\n",
    "    \n",
    "    cost_fn = ca.Function('J', [x], [J])\n",
    "    grad_fn = ca.Function('dJ', [x], [grad_J])\n",
    "    \n",
    "    y = y_init\n",
    "    history = {'y': [y], 'cost': [float(cost_fn(y))], \n",
    "               'true_cost': [total_cost(np.array([y]))[0]]}\n",
    "    \n",
    "    lr = 0.3\n",
    "    for i in range(100):\n",
    "        g = float(grad_fn(y))\n",
    "        y_new = y - lr * g\n",
    "        history['y'].append(y_new)\n",
    "        history['cost'].append(float(cost_fn(y_new)))\n",
    "        history['true_cost'].append(total_cost(np.array([y_new]))[0])\n",
    "        \n",
    "        if abs(g) < 1e-8:\n",
    "            break\n",
    "        y = y_new\n",
    "        lr *= 0.98\n",
    "    \n",
    "    return {'y': history['y'], 'cost': history['cost'], 'true_cost': history['true_cost'],\n",
    "            'x_opt': history['y'][-1], 'f_opt': history['true_cost'][-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal: x*=4.5455, J*=2.2727\n",
      "PCE (best-so-far): y_best=4.5457, cost_best=2.2727\n",
      "NGD: y=1.3988, cost=13.1642\n",
      "CasADi (k=2): y=9.4049, TRUE cost=28.2482\n"
     ]
    }
   ],
   "source": [
    "Y_INIT = 9.5  # Start from local minimum basin (for CasADi k=2)\n",
    "SIGMA = 3.0\n",
    "N_SAMPLES = 100\n",
    "N_ITERATIONS = 50\n",
    "COV_SCHEDULE = CovarianceSchedule.COSINE\n",
    "\n",
    "np.random.seed(42)\n",
    "pce_history = run_pce_with_history(cost_fn=total_cost, y_init=Y_INIT, sigma_init=SIGMA,\n",
    "    n_samples=N_SAMPLES, n_iterations=N_ITERATIONS, cov_schedule=COV_SCHEDULE)\n",
    "\n",
    "np.random.seed(42)\n",
    "ngd_history = run_ngd_with_history(cost_fn=total_cost, y_init=Y_INIT, sigma_init=SIGMA,\n",
    "    n_samples=N_SAMPLES, n_iterations=N_ITERATIONS, cov_schedule=COV_SCHEDULE)\n",
    "\n",
    "casadi_history = run_casadi_with_history(y_init=Y_INIT, k=2)\n",
    "\n",
    "print(f\"Optimal: x*={X_STAR:.4f}, J*={OPTIMAL_COST:.4f}\")\n",
    "print(f\"PCE (best-so-far): y_best={pce_history['y_best'][-1]:.4f}, cost_best={pce_history['cost_best'][-1]:.4f}\")\n",
    "print(f\"NGD: y={ngd_history['y'][-1]:.4f}, cost={ngd_history['cost'][-1]:.4f}\")\n",
    "print(f\"CasADi (k=2): y={casadi_history['x_opt']:.4f}, TRUE cost={casadi_history['f_opt']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Visualization (3×3 Layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iteration(iteration: int):\n",
    "    casadi_iter = min(iteration, len(casadi_history['y']) - 1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    gs = GridSpec(3, 3, figure=fig, height_ratios=[1.2, 1, 1])\n",
    "    \n",
    "    x_plot = np.linspace(-2, 12, 500)\n",
    "    cost_curve = total_cost(x_plot)\n",
    "    \n",
    "    # Smooth cost for CasADi visualization\n",
    "    def smooth_cost(x_arr, k=2):\n",
    "        return np.array([(xv - 5)**2 + 0.1 * xv**2 + \n",
    "                 100.0 / (1 + np.exp(-k*(xv - 2))) / (1 + np.exp(k*(xv - 3))) +\n",
    "                 100.0 / (1 + np.exp(-k*(xv - 6))) / (1 + np.exp(k*(xv - 8)))\n",
    "                 for xv in x_arr])\n",
    "    \n",
    "    # TOP LEFT: PCE\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    ax.plot(x_plot, cost_curve, 'k-', lw=2, label='J(x)')\n",
    "    ax.axvline(X_STAR, color='red', ls='--', lw=2, alpha=0.7, label=f'x*={X_STAR:.2f}')\n",
    "    ax.axvspan(2, 3, alpha=0.3, color='orange', label='Barriers')\n",
    "    ax.axvspan(6, 8, alpha=0.3, color='orange')\n",
    "    if iteration < len(pce_history['samples']):\n",
    "        samples = pce_history['samples'][iteration]\n",
    "        costs = pce_history['sample_costs'][iteration]\n",
    "        elite_idx = pce_history['elite_indices'][iteration]\n",
    "        elite_weights = pce_history['elite_weights'][iteration]\n",
    "        ax.scatter(samples, costs, c='lightgreen', s=40, alpha=0.6, edgecolors='gray', linewidths=0.5)\n",
    "        sizes = 50 + 300 * elite_weights / elite_weights.max()\n",
    "        ax.scatter(samples[elite_idx], costs[elite_idx], c='green', s=sizes, edgecolors='darkgreen', linewidths=1.5, alpha=0.8)\n",
    "    # Show both raw and best trajectories\n",
    "    y_hist = pce_history['y'][:iteration+2]\n",
    "    y_best_hist = pce_history['y_best'][:iteration+2]\n",
    "    cost_hist = pce_history['cost'][:iteration+2]\n",
    "    cost_best_hist = pce_history['cost_best'][:iteration+2]\n",
    "    ax.plot(y_hist, cost_hist, 'lightgreen', lw=1, alpha=0.4)\n",
    "    ax.plot(y_best_hist, cost_best_hist, 'g-', lw=2, alpha=0.8)\n",
    "    ax.scatter([pce_history['y_best'][iteration]], [pce_history['cost_best'][iteration]], \n",
    "               c='green', s=200, marker='*', edgecolors='darkgreen', linewidths=2)\n",
    "    ax.annotate(f'Iter {iteration}\\ny_best = {pce_history[\"y_best\"][iteration]:.3f}\\nCost = {pce_history[\"cost_best\"][iteration]:.2f}', \n",
    "                xy=(0.02, 0.98), xycoords='axes fraction', fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "    ax.set_xlabel('x'); ax.set_ylabel('J(x)')\n",
    "    ax.set_title('PCE (best-so-far)', fontsize=14, fontweight='bold', color='green')\n",
    "    ax.legend(loc='upper right', fontsize=7); ax.set_xlim(-2, 12); ax.set_ylim(0, 50); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # TOP MIDDLE: NGD\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "    ax.plot(x_plot, cost_curve, 'k-', lw=2, label='J(x)')\n",
    "    ax.axvline(X_STAR, color='red', ls='--', lw=2, alpha=0.7, label=f'x*={X_STAR:.2f}')\n",
    "    ax.axvspan(2, 3, alpha=0.3, color='orange', label='Barriers')\n",
    "    ax.axvspan(6, 8, alpha=0.3, color='orange')\n",
    "    if iteration < len(ngd_history['samples']):\n",
    "        samples = ngd_history['samples'][iteration]\n",
    "        costs = ngd_history['sample_costs'][iteration]\n",
    "        epsilon = ngd_history['epsilon'][iteration]\n",
    "        ax.scatter(samples, costs, c='lightblue', s=40, alpha=0.6, edgecolors='gray', linewidths=0.5)\n",
    "        contributions = costs * epsilon\n",
    "        high_mask = np.abs(contributions) > np.percentile(np.abs(contributions), 90)\n",
    "        ax.scatter(samples[high_mask], costs[high_mask], c='blue', s=80, edgecolors='darkblue', linewidths=1.5, alpha=0.8)\n",
    "    y_hist = ngd_history['y'][:iteration+2]\n",
    "    cost_hist = ngd_history['cost'][:iteration+2]\n",
    "    ax.plot(y_hist, cost_hist, 'b-', lw=2, alpha=0.5)\n",
    "    ax.scatter([ngd_history['y'][iteration]], [ngd_history['cost'][iteration]], \n",
    "               c='blue', s=200, marker='*', edgecolors='darkblue', linewidths=2)\n",
    "    ax.annotate(f'Iter {iteration}\\ny = {ngd_history[\"y\"][iteration]:.3f}\\nCost = {ngd_history[\"cost\"][iteration]:.2f}', \n",
    "                xy=(0.02, 0.98), xycoords='axes fraction', fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "    ax.set_xlabel('x'); ax.set_ylabel('J(x)')\n",
    "    ax.set_title('NGD', fontsize=14, fontweight='bold', color='blue')\n",
    "    ax.legend(loc='upper right', fontsize=7); ax.set_xlim(-2, 12); ax.set_ylim(0, 50); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # TOP RIGHT: CasADi\n",
    "    ax = fig.add_subplot(gs[0, 2])\n",
    "    ax.plot(x_plot, cost_curve, 'k-', lw=2, label='True J(x)')\n",
    "    ax.plot(x_plot, smooth_cost(x_plot), 'purple', lw=1.5, ls='--', alpha=0.5, label='Smooth J (k=2)')\n",
    "    ax.axvline(X_STAR, color='red', ls='--', lw=2, alpha=0.7)\n",
    "    ax.axvspan(2, 3, alpha=0.3, color='orange')\n",
    "    ax.axvspan(6, 8, alpha=0.3, color='orange')\n",
    "    y_hist_ca = casadi_history['y'][:casadi_iter+2]\n",
    "    cost_hist_ca = casadi_history['true_cost'][:casadi_iter+2]\n",
    "    ax.plot(y_hist_ca, cost_hist_ca, 'purple', lw=2, alpha=0.5)\n",
    "    ax.scatter(y_hist_ca[:-1], cost_hist_ca[:-1], c='purple', s=60, alpha=0.4, marker='o')\n",
    "    ax.scatter([casadi_history['y'][casadi_iter]], [casadi_history['true_cost'][casadi_iter]], \n",
    "               c='purple', s=200, marker='*', edgecolors='darkmagenta', linewidths=2)\n",
    "    ax.annotate(f'Iter {casadi_iter}\\ny = {casadi_history[\"y\"][casadi_iter]:.3f}\\nTRUE Cost = {casadi_history[\"true_cost\"][casadi_iter]:.2f}', \n",
    "                xy=(0.02, 0.98), xycoords='axes fraction', fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lavender', alpha=0.7))\n",
    "    ax.set_xlabel('x'); ax.set_ylabel('J(x)')\n",
    "    ax.set_title('CasADi k=2 (smooth barrier)', fontsize=14, fontweight='bold', color='purple')\n",
    "    ax.legend(loc='upper right', fontsize=7); ax.set_xlim(-2, 12); ax.set_ylim(0, 50); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # MIDDLE ROW: y trajectory\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "    ax.plot(pce_history['y'], 'lightgreen', lw=1, alpha=0.4, label='Raw y')\n",
    "    ax.plot(pce_history['y_best'], 'g-', lw=2, label='y_best')\n",
    "    ax.axhline(X_STAR, color='red', ls='--', lw=1.5, alpha=0.7, label='x*')\n",
    "    ax.axhspan(2, 3, alpha=0.15, color='orange'); ax.axhspan(6, 8, alpha=0.15, color='orange')\n",
    "    ax.scatter([iteration], [pce_history['y_best'][iteration]], c='green', s=150, zorder=10, marker='*')\n",
    "    ax.axvline(iteration, color='gray', ls='--', lw=1, alpha=0.5)\n",
    "    ax.set_xlabel('Iteration'); ax.set_ylabel('y')\n",
    "    ax.set_title('PCE: y_best never regresses', fontsize=12, fontweight='bold', color='green')\n",
    "    ax.legend(loc='upper right', fontsize=8); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = fig.add_subplot(gs[1, 1])\n",
    "    ax.plot(ngd_history['y'], 'b-', lw=2)\n",
    "    ax.axhline(X_STAR, color='red', ls='--', lw=1.5, alpha=0.7, label='x*')\n",
    "    ax.axhspan(2, 3, alpha=0.15, color='orange'); ax.axhspan(6, 8, alpha=0.15, color='orange')\n",
    "    ax.scatter([iteration], [ngd_history['y'][iteration]], c='blue', s=150, zorder=10, marker='*')\n",
    "    ax.axvline(iteration, color='gray', ls='--', lw=1, alpha=0.5)\n",
    "    ax.set_xlabel('Iteration'); ax.set_ylabel('y')\n",
    "    ax.set_title('NGD: y Trajectory', fontsize=12, fontweight='bold', color='blue')\n",
    "    ax.legend(loc='upper right', fontsize=8); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = fig.add_subplot(gs[1, 2])\n",
    "    ax.plot(casadi_history['y'], 'purple', lw=2, marker='o', markersize=4)\n",
    "    ax.axhline(X_STAR, color='red', ls='--', lw=1.5, alpha=0.7, label='x*')\n",
    "    ax.axhspan(2, 3, alpha=0.15, color='orange'); ax.axhspan(6, 8, alpha=0.15, color='orange')\n",
    "    ax.scatter([casadi_iter], [casadi_history['y'][casadi_iter]], c='purple', s=150, zorder=10, marker='*')\n",
    "    ax.axvline(casadi_iter, color='gray', ls='--', lw=1, alpha=0.5)\n",
    "    ax.set_xlabel('Iteration'); ax.set_ylabel('y')\n",
    "    ax.set_title('CasADi: stuck in local min', fontsize=12, fontweight='bold', color='purple')\n",
    "    ax.legend(loc='upper right', fontsize=8); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # BOTTOM ROW: Cost convergence\n",
    "    ax = fig.add_subplot(gs[2, 0])\n",
    "    ax.plot(pce_history['cost'], 'lightgreen', lw=1, alpha=0.4, label='Raw cost')\n",
    "    ax.plot(pce_history['cost_best'], 'g-', lw=2, label='cost_best')\n",
    "    ax.axhline(OPTIMAL_COST, color='red', ls='--', lw=1.5, alpha=0.7, label=f'Opt={OPTIMAL_COST:.2f}')\n",
    "    ax.scatter([iteration], [pce_history['cost_best'][iteration]], c='green', s=150, zorder=10, marker='*')\n",
    "    ax.axvline(iteration, color='gray', ls='--', lw=1, alpha=0.5)\n",
    "    ax.set_xlabel('Iteration'); ax.set_ylabel('Cost')\n",
    "    ax.set_title('PCE: cost_best monotonic ↓', fontsize=12, fontweight='bold', color='green')\n",
    "    ax.set_yscale('log'); ax.legend(loc='upper right', fontsize=8); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = fig.add_subplot(gs[2, 1])\n",
    "    ax.plot(ngd_history['cost'], 'b-', lw=2)\n",
    "    ax.axhline(OPTIMAL_COST, color='red', ls='--', lw=1.5, alpha=0.7, label=f'Opt={OPTIMAL_COST:.2f}')\n",
    "    ax.scatter([iteration], [ngd_history['cost'][iteration]], c='blue', s=150, zorder=10, marker='*')\n",
    "    ax.axvline(iteration, color='gray', ls='--', lw=1, alpha=0.5)\n",
    "    ax.set_xlabel('Iteration'); ax.set_ylabel('Cost')\n",
    "    ax.set_title('NGD: Cost', fontsize=12, fontweight='bold', color='blue')\n",
    "    ax.set_yscale('log'); ax.legend(loc='upper right', fontsize=8); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = fig.add_subplot(gs[2, 2])\n",
    "    ax.plot(casadi_history['true_cost'], 'purple', lw=2, marker='o', markersize=4)\n",
    "    ax.axhline(OPTIMAL_COST, color='red', ls='--', lw=1.5, alpha=0.7, label=f'Opt={OPTIMAL_COST:.2f}')\n",
    "    ax.scatter([casadi_iter], [casadi_history['true_cost'][casadi_iter]], c='purple', s=150, zorder=10, marker='*')\n",
    "    ax.axvline(casadi_iter, color='gray', ls='--', lw=1, alpha=0.5)\n",
    "    ax.set_xlabel('Iteration'); ax.set_ylabel('TRUE Cost')\n",
    "    ax.set_title('CasADi: TRUE Cost', fontsize=12, fontweight='bold', color='purple')\n",
    "    ax.set_yscale('log'); ax.legend(loc='upper right', fontsize=8); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3812a053fe41908dfce013d83850b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='Iteration:', max=49, style=Slid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(\n",
    "    plot_iteration,\n",
    "    iteration=IntSlider(min=0, max=N_ITERATIONS-1, step=1, value=0,\n",
    "        description='Iteration:', continuous_update=False, style={'description_width': 'initial'})\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
