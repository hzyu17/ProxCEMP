{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive PCE & NGD Visualization\n",
    "\n",
    "Use the slider to step through iterations and see how both algorithms evolve.\n",
    "\n",
    "**Cost function:** $J(x) = (x - 5)^2 + 0.1 x^2$ (state cost + control cost)\n",
    "\n",
    "**Optimal:** $x^* = \\frac{50}{11} \\approx 4.545$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from ipywidgets import interact, IntSlider\n",
    "from IPython.display import display\n",
    "from enum import Enum\n",
    "import casadi as ca\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_state_cost(x: np.ndarray, x_star: float = 5.0) -> np.ndarray:\n",
    "    return (x - x_star) ** 2\n",
    "\n",
    "def control_cost(x: np.ndarray, R: float = 0.1) -> np.ndarray:\n",
    "    return R * x ** 2\n",
    "\n",
    "def total_cost(x: np.ndarray, x_star: float = 5.0, R: float = 0.1) -> np.ndarray:\n",
    "    return quadratic_state_cost(x, x_star) + control_cost(x, R)\n",
    "\n",
    "X_STAR = 50 / 11\n",
    "OPTIMAL_COST = total_cost(np.array([X_STAR]))[0]\n",
    "print(f\"Optimal x* = {X_STAR:.4f}\")\n",
    "print(f\"Optimal cost J(x*) = {OPTIMAL_COST:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovarianceSchedule(Enum):\n",
    "    CONSTANT = 0\n",
    "    LINEAR = 1\n",
    "    EXPONENTIAL = 2\n",
    "    COSINE = 3\n",
    "    STEP = 4\n",
    "    ADAPTIVE = 5\n",
    "\n",
    "def compute_covariance_scale(\n",
    "    iteration: int, n_iterations: int, schedule: CovarianceSchedule,\n",
    "    cov_scale_initial: float = 1.0, cov_scale_final: float = 0.01,\n",
    "    cov_decay_rate: float = 0.95, cov_step_factor: float = 0.5,\n",
    "    cov_step_interval: int = 10, cov_adaptive_threshold: float = 0.01,\n",
    "    cov_scale_current: float = None, prev_cost: float = 0.0, curr_cost: float = 0.0,\n",
    ") -> float:\n",
    "    t = float(iteration - 1)\n",
    "    T = float(n_iterations)\n",
    "    \n",
    "    if schedule == CovarianceSchedule.CONSTANT:\n",
    "        return cov_scale_initial\n",
    "    elif schedule == CovarianceSchedule.LINEAR:\n",
    "        return cov_scale_initial + (cov_scale_final - cov_scale_initial) * (t / T)\n",
    "    elif schedule == CovarianceSchedule.EXPONENTIAL:\n",
    "        return max(cov_scale_final, cov_scale_initial * (cov_decay_rate ** t))\n",
    "    elif schedule == CovarianceSchedule.COSINE:\n",
    "        return cov_scale_final + 0.5 * (cov_scale_initial - cov_scale_final) * (1.0 + np.cos(np.pi * t / T))\n",
    "    elif schedule == CovarianceSchedule.STEP:\n",
    "        return max(cov_scale_final, cov_scale_initial * (cov_step_factor ** np.floor(t / cov_step_interval)))\n",
    "    elif schedule == CovarianceSchedule.ADAPTIVE:\n",
    "        if cov_scale_current is None:\n",
    "            cov_scale_current = cov_scale_initial\n",
    "        if iteration <= 1:\n",
    "            return cov_scale_current\n",
    "        improvement = (prev_cost - curr_cost) / (abs(prev_cost) + 1e-6)\n",
    "        if improvement > cov_adaptive_threshold:\n",
    "            cov_scale_current *= cov_decay_rate\n",
    "        elif improvement < 0:\n",
    "            cov_scale_current *= (1.0 + 0.1 * (1.0 - cov_decay_rate))\n",
    "        return np.clip(cov_scale_current, cov_scale_final, cov_scale_initial)\n",
    "    else:\n",
    "        return cov_scale_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCE Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pce_with_history(\n",
    "    cost_fn, y_init: float = 0.0, sigma_init: float = 2.0,\n",
    "    n_samples: int = 100, n_iterations: int = 50, elite_ratio: float = 0.1,\n",
    "    ema_alpha: float = 0.5, gamma: float = 1.0, temperature: float = 1.5,\n",
    "    temperature_final: float = 0.05, R: float = 0.1,\n",
    "    cov_schedule: CovarianceSchedule = CovarianceSchedule.COSINE,\n",
    "    cov_scale_initial: float = 1.0, cov_scale_final: float = 0.01,\n",
    "    cov_decay_rate: float = 0.95,\n",
    "):\n",
    "    y = y_init\n",
    "    sigma_base = sigma_init\n",
    "    n_elites = max(1, int(n_samples * elite_ratio))\n",
    "    cov_scale_current = cov_scale_initial\n",
    "    prev_cost = cost_fn(np.array([y]))[0]\n",
    "    \n",
    "    history = {\n",
    "        'y': [y], 'sigma': [sigma_base * cov_scale_initial],\n",
    "        'cov_scale': [cov_scale_initial], 'cost': [prev_cost],\n",
    "        'temperature': [temperature], 'samples': [], 'sample_costs': [],\n",
    "        'elite_indices': [], 'elite_weights': [], 'weighted_y': [],\n",
    "    }\n",
    "    \n",
    "    for iteration in range(1, n_iterations + 1):\n",
    "        progress = (iteration - 1) / max(1, n_iterations - 1)\n",
    "        current_temp = temperature * (temperature_final / temperature) ** progress\n",
    "        \n",
    "        curr_cost = cost_fn(np.array([y]))[0]\n",
    "        cov_scale = compute_covariance_scale(\n",
    "            iteration, n_iterations, cov_schedule,\n",
    "            cov_scale_initial, cov_scale_final, cov_decay_rate,\n",
    "            cov_scale_current=cov_scale_current, prev_cost=prev_cost, curr_cost=curr_cost,\n",
    "        )\n",
    "        cov_scale_current = cov_scale\n",
    "        effective_sigma = sigma_base * cov_scale\n",
    "        \n",
    "        epsilon = effective_sigma * np.random.randn(n_samples)\n",
    "        samples = y + epsilon\n",
    "        costs = cost_fn(samples)\n",
    "        indices = np.argsort(costs)\n",
    "        elite_indices = indices[:n_elites]\n",
    "        \n",
    "        weights = np.zeros(n_samples)\n",
    "        for m in elite_indices:\n",
    "            reg_term = epsilon[m] * R * y\n",
    "            exponent = (-gamma * (costs[m] + reg_term)) / current_temp\n",
    "            weights[m] = exponent\n",
    "        \n",
    "        max_exp = np.max(weights[elite_indices])\n",
    "        for m in elite_indices:\n",
    "            weights[m] = np.exp(weights[m] - max_exp)\n",
    "        weights /= (np.sum(weights[elite_indices]) + 1e-10)\n",
    "        \n",
    "        x_weighted = sum(weights[m] * (y + epsilon[m]) for m in elite_indices)\n",
    "        \n",
    "        history['samples'].append(samples.copy())\n",
    "        history['sample_costs'].append(costs.copy())\n",
    "        history['elite_indices'].append(elite_indices.copy())\n",
    "        history['elite_weights'].append(weights[elite_indices].copy())\n",
    "        history['weighted_y'].append(x_weighted)\n",
    "        \n",
    "        y = (1 - ema_alpha) * y + ema_alpha * x_weighted\n",
    "        \n",
    "        history['y'].append(y)\n",
    "        history['sigma'].append(effective_sigma)\n",
    "        history['cov_scale'].append(cov_scale)\n",
    "        history['cost'].append(cost_fn(np.array([y]))[0])\n",
    "        history['temperature'].append(current_temp)\n",
    "        prev_cost = curr_cost\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGD Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ngd_with_history(\n",
    "    cost_fn, y_init: float = 0.0, sigma_init: float = 2.0,\n",
    "    n_samples: int = 100, n_iterations: int = 50, learning_rate: float = 0.1,\n",
    "    temperature: float = 1.0, cov_schedule: CovarianceSchedule = CovarianceSchedule.COSINE,\n",
    "    cov_scale_initial: float = 1.0, cov_scale_final: float = 0.01,\n",
    "    cov_decay_rate: float = 0.95,\n",
    "):\n",
    "    y = y_init\n",
    "    sigma_base = sigma_init\n",
    "    cov_scale_current = cov_scale_initial\n",
    "    prev_cost = cost_fn(np.array([y]))[0]\n",
    "    \n",
    "    history = {\n",
    "        'y': [y], 'sigma': [sigma_base * cov_scale_initial],\n",
    "        'cov_scale': [cov_scale_initial], 'cost': [prev_cost],\n",
    "        'temperature': [temperature], 'learning_rate': [learning_rate],\n",
    "        'samples': [], 'sample_costs': [], 'gradient': [], 'epsilon': [],\n",
    "    }\n",
    "    \n",
    "    for iteration in range(1, n_iterations + 1):\n",
    "        curr_cost = cost_fn(np.array([y]))[0]\n",
    "        cov_scale = compute_covariance_scale(\n",
    "            iteration, n_iterations, cov_schedule,\n",
    "            cov_scale_initial, cov_scale_final, cov_decay_rate,\n",
    "            cov_scale_current=cov_scale_current, prev_cost=prev_cost, curr_cost=curr_cost,\n",
    "        )\n",
    "        cov_scale_current = cov_scale\n",
    "        effective_sigma = sigma_base * cov_scale\n",
    "        \n",
    "        epsilon = effective_sigma * np.random.randn(n_samples)\n",
    "        samples = y + epsilon\n",
    "        costs = cost_fn(samples)\n",
    "        costs = np.where(np.isfinite(costs), costs, 1e6)\n",
    "        \n",
    "        natural_gradient = np.mean((costs / temperature) * epsilon)\n",
    "        \n",
    "        history['samples'].append(samples.copy())\n",
    "        history['sample_costs'].append(costs.copy())\n",
    "        history['gradient'].append(natural_gradient)\n",
    "        history['epsilon'].append(epsilon.copy())\n",
    "        \n",
    "        y = y - learning_rate * natural_gradient\n",
    "        \n",
    "        history['y'].append(y)\n",
    "        history['sigma'].append(effective_sigma)\n",
    "        history['cov_scale'].append(cov_scale)\n",
    "        history['cost'].append(cost_fn(np.array([y]))[0])\n",
    "        history['temperature'].append(temperature)\n",
    "        history['learning_rate'].append(learning_rate)\n",
    "        prev_cost = curr_cost\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CasADi Solver (Newton's Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_casadi_with_history(y_init: float = 0.0, x_star: float = 5.0, R: float = 0.1):\n",
    "    \"\"\"\n",
    "    Solve using CasADi with Newton's method.\n",
    "    min_x  (x - x_star)² + R * x²\n",
    "    \"\"\"\n",
    "    x = ca.SX.sym('x')\n",
    "    J = (x - x_star)**2 + R * x**2\n",
    "    grad_J = ca.gradient(J, x)\n",
    "    hess_J = ca.hessian(J, x)[0]\n",
    "    \n",
    "    cost_fn = ca.Function('J', [x], [J])\n",
    "    grad_fn = ca.Function('dJ', [x], [grad_J])\n",
    "    hess_fn = ca.Function('ddJ', [x], [hess_J])\n",
    "    \n",
    "    y = y_init\n",
    "    history = {'y': [y], 'cost': [float(cost_fn(y))]}\n",
    "    \n",
    "    for i in range(20):\n",
    "        g = float(grad_fn(y))\n",
    "        H = float(hess_fn(y))\n",
    "        \n",
    "        if abs(H) > 1e-12:\n",
    "            step = -g / H\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        y_new = y + step\n",
    "        history['y'].append(y_new)\n",
    "        history['cost'].append(float(cost_fn(y_new)))\n",
    "        \n",
    "        if abs(g) < 1e-10:\n",
    "            break\n",
    "        y = y_new\n",
    "    \n",
    "    return {\n",
    "        'y': history['y'],\n",
    "        'cost': history['cost'],\n",
    "        'x_opt': history['y'][-1],\n",
    "        'f_opt': history['cost'][-1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_INIT = 0.0\n",
    "SIGMA = 2.0\n",
    "N_SAMPLES = 100\n",
    "N_ITERATIONS = 50\n",
    "COV_SCHEDULE = CovarianceSchedule.COSINE\n",
    "\n",
    "pce_history = run_pce_with_history(\n",
    "    cost_fn=total_cost, y_init=Y_INIT, sigma_init=SIGMA,\n",
    "    n_samples=N_SAMPLES, n_iterations=N_ITERATIONS,\n",
    "    cov_schedule=COV_SCHEDULE,\n",
    ")\n",
    "\n",
    "ngd_history = run_ngd_with_history(\n",
    "    cost_fn=total_cost, y_init=Y_INIT, sigma_init=SIGMA,\n",
    "    n_samples=N_SAMPLES, n_iterations=N_ITERATIONS,\n",
    "    cov_schedule=COV_SCHEDULE,\n",
    ")\n",
    "\n",
    "casadi_history = run_casadi_with_history(y_init=Y_INIT)\n",
    "\n",
    "print(f\"Covariance schedule: {COV_SCHEDULE.name}\")\n",
    "print(f\"PCE:    y={pce_history['y'][-1]:.4f}, cost={pce_history['cost'][-1]:.4f}\")\n",
    "print(f\"NGD:    y={ngd_history['y'][-1]:.4f}, cost={ngd_history['cost'][-1]:.4f}\")\n",
    "print(f\"CasADi: y={casadi_history['x_opt']:.4f}, cost={casadi_history['f_opt']:.6f} ({len(casadi_history['y'])-1} iters)\")\n",
    "print(f\"Optimal: x*={X_STAR:.4f}, cost={OPTIMAL_COST:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Visualization\n",
    "\n",
    "**Layout:**\n",
    "- Top row: PCE (left), NGD (right)\n",
    "- Bottom row: Cost Convergence, Covariance Schedule, CasADi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iteration(iteration: int):\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    gs = GridSpec(2, 3, figure=fig, height_ratios=[1.2, 1])\n",
    "    \n",
    "    x_plot = np.linspace(-3, 10, 500)\n",
    "    cost_curve = total_cost(x_plot)\n",
    "    \n",
    "    # TOP LEFT: PCE\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    ax.plot(x_plot, cost_curve, 'k-', lw=2, label='J(x)', zorder=1)\n",
    "    ax.axvline(X_STAR, color='red', ls='--', lw=2, alpha=0.7, label=f'x* = {X_STAR:.2f}')\n",
    "    \n",
    "    if iteration < len(pce_history['samples']):\n",
    "        samples = pce_history['samples'][iteration]\n",
    "        costs = pce_history['sample_costs'][iteration]\n",
    "        elite_idx = pce_history['elite_indices'][iteration]\n",
    "        elite_weights = pce_history['elite_weights'][iteration]\n",
    "        weighted_y = pce_history['weighted_y'][iteration]\n",
    "        \n",
    "        ax.scatter(samples, costs, c='lightgreen', s=40, alpha=0.6, label='Samples', zorder=2, edgecolors='gray', linewidths=0.5)\n",
    "        sizes = 50 + 300 * elite_weights / elite_weights.max()\n",
    "        ax.scatter(samples[elite_idx], costs[elite_idx], c='green', s=sizes, label='Elites', zorder=3, edgecolors='darkgreen', linewidths=1.5, alpha=0.8)\n",
    "        ax.axvline(weighted_y, color='darkgreen', ls='-', lw=2, label=f'Weighted y = {weighted_y:.2f}', zorder=4)\n",
    "    \n",
    "    y_hist = pce_history['y'][:iteration+2]\n",
    "    cost_hist = [total_cost(np.array([val]))[0] for val in y_hist]\n",
    "    ax.plot(y_hist, cost_hist, 'g-', lw=2, alpha=0.5, zorder=5)\n",
    "    ax.scatter(y_hist[:-1], cost_hist[:-1], c='green', s=60, alpha=0.4, zorder=5, marker='o')\n",
    "    ax.scatter([pce_history['y'][iteration]], [pce_history['cost'][iteration]], c='green', s=200, zorder=6, marker='*', edgecolors='darkgreen', linewidths=2)\n",
    "    \n",
    "    ax.annotate(f'Iter {iteration}\\nTemp = {pce_history[\"temperature\"][iteration]:.3f}\\nσ = {pce_history[\"sigma\"][iteration]:.3f}\\nCost = {pce_history[\"cost\"][iteration]:.4f}', \n",
    "                xy=(0.02, 0.98), xycoords='axes fraction', fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "    ax.set_xlabel('x'); ax.set_ylabel('J(x)'); ax.set_title('PCE', fontsize=14, fontweight='bold', color='green')\n",
    "    ax.legend(loc='upper right', fontsize=8); ax.set_xlim(-3, 10); ax.set_ylim(-1, 30); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # TOP RIGHT: NGD (spanning 2 columns)\n",
    "    ax = fig.add_subplot(gs[0, 1:])\n",
    "    ax.plot(x_plot, cost_curve, 'k-', lw=2, label='J(x)', zorder=1)\n",
    "    ax.axvline(X_STAR, color='red', ls='--', lw=2, alpha=0.7, label=f'x* = {X_STAR:.2f}')\n",
    "    \n",
    "    if iteration < len(ngd_history['samples']):\n",
    "        samples = ngd_history['samples'][iteration]\n",
    "        costs = ngd_history['sample_costs'][iteration]\n",
    "        epsilon = ngd_history['epsilon'][iteration]\n",
    "        \n",
    "        ax.scatter(samples, costs, c='lightblue', s=40, alpha=0.6, label='Samples', zorder=2, edgecolors='gray', linewidths=0.5)\n",
    "        contributions = (costs / ngd_history['temperature'][iteration]) * epsilon\n",
    "        high_mask = np.abs(contributions) > np.percentile(np.abs(contributions), 90)\n",
    "        ax.scatter(samples[high_mask], costs[high_mask], c='blue', s=80, label='High contrib.', zorder=3, edgecolors='darkblue', linewidths=1.5, alpha=0.8)\n",
    "    \n",
    "    y_hist = ngd_history['y'][:iteration+2]\n",
    "    cost_hist = [total_cost(np.array([val]))[0] for val in y_hist]\n",
    "    ax.plot(y_hist, cost_hist, 'b-', lw=2, alpha=0.5, zorder=5)\n",
    "    ax.scatter(y_hist[:-1], cost_hist[:-1], c='blue', s=60, alpha=0.4, zorder=5, marker='o')\n",
    "    ax.scatter([ngd_history['y'][iteration]], [ngd_history['cost'][iteration]], c='blue', s=200, zorder=6, marker='*', edgecolors='darkblue', linewidths=2)\n",
    "    \n",
    "    if iteration < len(ngd_history['gradient']):\n",
    "        ax.annotate(f'Iter {iteration}\\n∇ = {ngd_history[\"gradient\"][iteration]:.3f}\\nσ = {ngd_history[\"sigma\"][iteration]:.3f}\\nCost = {ngd_history[\"cost\"][iteration]:.4f}', \n",
    "                    xy=(0.02, 0.98), xycoords='axes fraction', fontsize=10, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "    ax.set_xlabel('x'); ax.set_ylabel('J(x)'); ax.set_title('NGD', fontsize=14, fontweight='bold', color='blue')\n",
    "    ax.legend(loc='upper right', fontsize=8); ax.set_xlim(-3, 10); ax.set_ylim(-1, 30); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # BOTTOM LEFT: Cost Convergence\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "    ax.plot(pce_history['cost'], 'g-', lw=2, label='PCE')\n",
    "    ax.plot(ngd_history['cost'], 'b-', lw=2, label='NGD')\n",
    "    ax.axhline(OPTIMAL_COST, color='red', ls='--', lw=1.5, alpha=0.7, label=f'Optimal')\n",
    "    ax.scatter([iteration], [pce_history['cost'][iteration]], c='green', s=150, zorder=10, marker='*', edgecolors='darkgreen', linewidths=2)\n",
    "    ax.scatter([iteration], [ngd_history['cost'][iteration]], c='blue', s=150, zorder=10, marker='*', edgecolors='darkblue', linewidths=2)\n",
    "    ax.axvline(iteration, color='gray', ls='--', lw=1, alpha=0.5)\n",
    "    ax.set_xlabel('Iteration'); ax.set_ylabel('Cost J(y)'); ax.set_title('Cost Convergence', fontsize=14, fontweight='bold')\n",
    "    ax.set_yscale('log'); ax.set_xlim(-1, len(pce_history['cost'])); ax.legend(loc='upper right', fontsize=9); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # BOTTOM MIDDLE: Covariance Schedule\n",
    "    ax = fig.add_subplot(gs[1, 1])\n",
    "    ax.plot(pce_history['sigma'], 'g-', lw=2, label='PCE σ')\n",
    "    ax.plot(ngd_history['sigma'], 'b-', lw=2, label='NGD σ')\n",
    "    ax.scatter([iteration], [pce_history['sigma'][iteration]], c='green', s=150, zorder=10, marker='*', edgecolors='darkgreen', linewidths=2)\n",
    "    ax.scatter([iteration], [ngd_history['sigma'][iteration]], c='blue', s=150, zorder=10, marker='*', edgecolors='darkblue', linewidths=2)\n",
    "    ax.axvline(iteration, color='gray', ls='--', lw=1, alpha=0.5)\n",
    "    ax.set_xlabel('Iteration'); ax.set_ylabel('σ (effective)'); ax.set_title(f'Covariance ({COV_SCHEDULE.name})', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlim(-1, len(pce_history['sigma'])); ax.legend(loc='upper right', fontsize=9); ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # BOTTOM RIGHT: CasADi\n",
    "    ax = fig.add_subplot(gs[1, 2])\n",
    "    casadi_iters = np.arange(len(casadi_history['cost']))\n",
    "    ax.plot(casadi_iters, casadi_history['cost'], 'purple', lw=2, marker='o', markersize=8, label='CasADi (Newton)')\n",
    "    ax.axhline(OPTIMAL_COST, color='red', ls='--', lw=1.5, alpha=0.7, label=f'Optimal')\n",
    "    ax.scatter([len(casadi_history['cost'])-1], [casadi_history['f_opt']], c='purple', s=200, zorder=10, marker='*', edgecolors='darkmagenta', linewidths=2)\n",
    "    ax.set_xlabel('Iteration'); ax.set_ylabel('Cost J(x)'); ax.set_title(f'CasADi (Newton) - {len(casadi_history[\"cost\"])-1} iters', fontsize=14, fontweight='bold', color='purple')\n",
    "    ax.set_yscale('log'); ax.set_xlim(-0.5, max(len(casadi_history['cost']), 5)); ax.legend(loc='upper right', fontsize=9); ax.grid(True, alpha=0.3)\n",
    "    ax.annotate(f'Final: x={casadi_history[\"x_opt\"]:.4f}\\nCost={casadi_history[\"f_opt\"]:.6f}', \n",
    "                xy=(0.98, 0.98), xycoords='axes fraction', fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='lavender', alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(\n",
    "    plot_iteration,\n",
    "    iteration=IntSlider(\n",
    "        min=0, max=min(len(pce_history['samples']), len(ngd_history['samples'])) - 1,\n",
    "        step=1, value=0, description='Iteration:',\n",
    "        continuous_update=False, style={'description_width': 'initial'}\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "def animate(delay: float = 0.3):\n",
    "    n_iter = min(len(pce_history['samples']), len(ngd_history['samples']))\n",
    "    for i in range(n_iter):\n",
    "        clear_output(wait=True)\n",
    "        plot_iteration(i)\n",
    "        time.sleep(delay)\n",
    "\n",
    "# Uncomment to run: animate(delay=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
