# =============================================================================
# Motion Planning Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# Environment Settings
# -----------------------------------------------------------------------------
environment:
  map_width: 800
  map_height: 600
  num_obstacles: 20
  obstacle_radius: 20.0
  clearance_distance: 100.0
  cost:
    epsilon_sdf: 1.0
    sigma_obs: 1.0

# -----------------------------------------------------------------------------
# Motion Planning Problem Definition
# -----------------------------------------------------------------------------
motion_planning:
  num_dimensions: 2
  num_discretization: 500
  total_time: 10.0
  node_collision_radius: 15.0
  start_position:
    - 50.0
    - 550.0
  goal_position:
    - 750.0
    - 50.0

# -----------------------------------------------------------------------------
# Experiment Settings
# -----------------------------------------------------------------------------
experiment:
  config_file: config.yaml
  random_seed: 19
  enable_logging: true
  log_directory: ./logs
  visualize_initial_state: false

# =============================================================================
# CasADi Motion Planner Configuration
# =============================================================================
# Supported solvers: lbfgs, ipopt, sqp, gd (gradient_descent), adam
# =============================================================================
casadi_planner:
  # --- Common Parameters ---
  solver: ipopt                    # Options: lbfgs, ipopt, sqp, gd, adam
  max_iterations: 500              # Max iterations for first-order methods (GD/Adam/L-BFGS)
  tolerance: 1e-6                  # Convergence tolerance (gradient norm)
  collision_weight: 10.0           # Weight for collision cost term
  finite_diff_eps: 1e-4            # Epsilon for finite difference gradients (fallback)
  verbose_solver: true             # Print optimization progress
  use_symbolic_collision: true     # Use analytical collision gradients (requires CasadiCollisionTask)

  # --- Objective Scaling ---
  scaling:
    use_objective_scaling: true
    objective_scale: 1e-4          # Scale factor for numerical stability

  # --- L-BFGS Parameters ---
  lbfgs:
    history_size: 10               # Number of past gradients to store

  # --- IPOPT Parameters (used as inner solver in SCP) ---
  ipopt:
    linear_solver: mumps           # Options: mumps, ma27, ma57, pardiso
    hessian_approximation: limited-memory  # Options: limited-memory, exact
    tol: 1e-4                      # IPOPT convergence tolerance
    acceptable_tol: 1e-2           # Acceptable tolerance for early termination
    acceptable_iter: 5             # Iterations at acceptable tolerance before stopping
    max_iter: 500                  # Max IPOPT iterations per subproblem
    max_cpu_time: 60.0             # Max CPU time in seconds
    print_level: 0                 # IPOPT verbosity (0-12)
    warm_start_init_point: 'yes'   # Enable warm starting between SCP iterations

  # --- Sequential Convex Programming (SCP) Parameters ---
  # Used by IPOPT and SQP solvers for handling non-convex collision costs
  scp:
    max_outer_iter: 100             # Max SCP outer iterations
    inner_max_iter: 200            # Max inner solver iterations per SCP step
    trust_region_init: 10.0        # Initial trust region radius
    trust_region_min: 1e-4         # Minimum trust region (triggers convergence)
    trust_region_max: 1000.0       # Maximum trust region radius
    trust_expand: 2.0              # Trust region expansion factor (good step)
    trust_shrink: 0.5              # Trust region shrink factor (bad step)
    accept_ratio: 0.1              # Min actual/predicted reduction to accept step
    good_ratio: 0.75               # Ratio threshold for trust region expansion
    convergence_tol: 1e-4          # Step size convergence tolerance
    cost_improvement_tol: 1e-4     # Relative cost improvement tolerance
    stall_limit: 10                # Max iterations without improvement

  # --- SQP Parameters ---
  sqp:
    qp_solver: qrqp                # Options: qpoases, osqp, hpipm, qrqp
    hessian_approximation: bfgs    # Options: bfgs, gauss-newton
    max_iter_ls: 20                # Max line search iterations
    beta: 0.5                      # Line search backtracking factor
    c1: 1e-4                       # Armijo condition parameter

  # --- Gradient Descent Parameters ---
  gradient_descent:
    learning_rate: 0.8           # Step size (reduced for stability)
    momentum: 0.9                  # Momentum coefficient
    use_nesterov: true             # Use Nesterov accelerated gradient
    lr_decay: 1.0                  # Learning rate decay (1.0 = no decay)

  # --- Adam Parameters ---
  adam:
    learning_rate: 0.8            # Step size
    beta1: 0.9                     # First moment decay
    beta2: 0.999                   # Second moment decay
    epsilon: 1e-8                  # Numerical stability constant

# =============================================================================
# Alternative Planner Configurations (for comparison)
# =============================================================================

# --- STOMP (Stochastic Trajectory Optimization) ---
stomp:
  num_iterations: 50
  num_rollouts: 100
  max_rollouts: 10
  num_iterations_after_valid: 10
  noise_stddev: 50.0               # ~5-10% of workspace diagonal
  noise_decay: 0.98
  exponentiated_cost_sensitivity: 5.0
  control_cost_weight: 10.0
  delta_t: 0.02                    # total_time / num_discretization

# =============================================================================
# PCE (Proximal Cross-Entropy) Planner - STOMP-Inspired Version
# =============================================================================
pce_planner:
  # ---------------------------------------------------------------------------
  # Core Algorithm Parameters
  # ---------------------------------------------------------------------------
  num_iterations: 50               # Maximum optimization iterations
  enable_early_termination: true
  num_iterations_after_valid: 10
  num_samples: 500                 # Number of trajectory samples per iteration
  elite_ratio: 0.8                # Fraction of samples to use as elites (0.0-1.0)
  
  # --- Temperature Schedule ---
  # Controls exploration vs exploitation tradeoff
  # Higher temperature = more uniform weighting across samples
  temperature: 1.0                 # Initial temperature
  temperature_final: 0.5         # Final temperature (annealed over iterations)
  
  # --- Update Parameters ---
  eta: 1.0                         # Proximal regularization strength
                                   # gamma = eta / (eta + 1) is auto-computed
  ema_alpha: 0.5                   # Exponential moving average blend factor
                                   # 0 = keep old trajectory, 1 = use new weighted mean
  
  # --- Convergence ---
  convergence_threshold: 1e-4      # Stop if cost change < threshold
  
  # --- Collision Parameters ---
  collision_clearance: 0.1         # Desired clearance from obstacles
  collision_threshold: 0.1         # Collision detection threshold
  
  # --- Covariance Schedule ---
  # Controls noise magnitude for exploration
  covariance_schedule: cosine      # Options: constant, linear, exponential, cosine, step, adaptive
  cov_scale_initial: 10.0          # Initial noise scale
  cov_scale_final: 1.0             # Final noise scale
  cov_decay_rate: 0.9              # Decay rate for exponential schedule
  cov_step_interval: 5             # Interval for step schedule
  cov_step_factor: 0.5             # Factor for step schedule
  cov_adaptive_threshold: 0.05     # Threshold for adaptive schedule
  
  # ---------------------------------------------------------------------------
  # Rollout Reuse Parameters (STOMP-Inspired)
  # ---------------------------------------------------------------------------
  # These parameters control reusing good samples from previous iterations
  # instead of generating all new samples. This can significantly improve
  # convergence speed by preserving promising trajectory regions.
  # ---------------------------------------------------------------------------
  
  enable_rollout_reuse: true       # Enable/disable rollout reuse feature
                                   # Set to false for vanilla PCE behavior
  
  # --- Reuse Quantity ---
  # Controls how many rollouts to keep from previous iteration
  # Auto-computed if set to 0: num_rollouts_reuse = num_elites * reuse_ratio
  reuse_ratio: 0.5                 # Fraction of elites to reuse (0.0-1.0)
                                   # 0.5 = reuse half of elite samples
  num_rollouts_reuse: 0            # Explicit count (0 = auto-compute from reuse_ratio)
  max_rollouts: 0                  # Max rollout storage (0 = auto-compute)
                                   # Auto: num_samples + num_rollouts_reuse + 1
  
  # --- Reuse Selection ---
  # Controls how rollouts are selected for reuse based on their cost
  exponentiated_cost_sensitivity: 10.0  # 'h' parameter in exp(-h * normalized_cost)
                                        # Higher = more selective (prefer best rollouts)
                                        # Lower = more uniform selection
                                        # Typical range: 1.0 - 20.0
  
  # --- Importance Weighting ---
  # Reused rollouts have their influence decayed over time to prevent
  # stale samples from dominating the optimization
  importance_weight_decay: 0.9     # Multiply weight by this each time reused
                                   # 0.9 = 90% weight retention per iteration
  importance_weight_min: 0.1       # Discard rollout when weight falls below this
                                   # Prevents very stale samples from being used

# =============================================================================
# PCE Planner Presets
# =============================================================================
# Uncomment one of these sections to use predefined parameter sets

# --- High Quality (slower, better solutions) ---
# pce_planner:
#   num_iterations: 100
#   num_samples: 1000
#   elite_ratio: 0.03
#   temperature: 3.0
#   temperature_final: 0.5
#   enable_rollout_reuse: true
#   reuse_ratio: 0.6
#   exponentiated_cost_sensitivity: 15.0

# --- Fast (quick approximate solutions) ---
# pce_planner:
#   num_iterations: 20
#   num_samples: 200
#   elite_ratio: 0.1
#   temperature: 8.0
#   temperature_final: 2.0
#   enable_rollout_reuse: true
#   reuse_ratio: 0.4
#   exponentiated_cost_sensitivity: 5.0

# --- No Reuse (vanilla PCE for comparison) ---
# pce_planner:
#   num_iterations: 50
#   num_samples: 500
#   elite_ratio: 0.05
#   enable_rollout_reuse: false

# --- NGD (Natural Gradient Descent) Planner ---
ngd_planner:
  num_iterations: 50
  num_samples: 500
  learning_rate: 5e-6
  temperature: 1.0
  temperature_final: 0.1
  ema_alpha: 0.3
  covariance_schedule: cosine
  cov_scale_initial: 10.0
  cov_scale_final: 0.1